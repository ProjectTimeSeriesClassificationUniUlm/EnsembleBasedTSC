{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 18:43:06.004415: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-18 18:43:06.131923: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-18 18:43:07.007008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/bwhpc/common/devel/cuda/11.8/lib64\n",
      "2023-01-18 18:43:07.007082: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/bwhpc/common/devel/cuda/11.8/lib64\n",
      "2023-01-18 18:43:07.007089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "sys.path.append(\"../../../../\")\n",
    "from src.Evaluation import plot_model_history\n",
    "from src.ModelBuilder import get_MLP, get_MCDCNN, get_Time_CNN, get_FCN, get_Encoder\n",
    "from src.LoadData import get_all_datasets_test_train_np_arrays\n",
    "from src.Helpers import append_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "path_to_datasets = \"../../../../datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datasets_test_train_data = get_all_datasets_test_train_np_arrays(path_to_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models_getter = [get_Encoder, ]\n",
    "models_names = [\"Encoder\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 18:43:16.422707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-18 18:43:17.618240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 88 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2023-01-18 18:43:17.619080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 88 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n",
      "2023-01-18 18:43:17.639586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 88.25M (92536832 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-01-18 18:43:17.646464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 88.25M (92536832 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "devices = tf.config.list_logical_devices('GPU') # Use this to run training just on GPUs\n",
    "#devices = tf.config.list_logical_devices()\n",
    "strategy = tf.distribute.MirroredStrategy(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:GPU:0', device_type='GPU'),\n",
       " LogicalDevice(name='/device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "path_persist_results = \"./training_res.csv\"\n",
    "if not (csv_path := Path(path_persist_results)).exists():\n",
    "    csv_path.touch()\n",
    "if len(csv_path.read_text()) == 0:\n",
    "    # Only write if the file is empty\n",
    "    columns = [\"dataset_name\", \"model_name\", \"test_loss\", \"test_acc\", \"confusion_matrix\", \"history\"]\n",
    "    append_to_csv(path_persist_results, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 20\n",
    "validation_split = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dad695c05f645a3914f9be1ae94325b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?dataset/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name:  abnormal_heartbeat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66d74427cb04aa8bcae7c9798ed65cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train on \"abnormal_heartbeat\":   0%|          | 0/1 [00:00<?, ?model/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  Encoder\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da29dc38d81b472d83ae6713cf38d7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoder: 0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 21 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 21 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 18:43:34.109302: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 90.48MiB (rounded to 94873600)requested by op model/conv1d/Conv1D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-01-18 18:43:34.109332: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-01-18 18:43:34.109341: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 47, Chunks in use: 47. 11.8KiB allocated for chunks. 11.8KiB in use in bin. 426B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109363: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 9, Chunks in use: 9. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 4.5KiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109368: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 17, Chunks in use: 17. 18.8KiB allocated for chunks. 18.8KiB in use in bin. 17.6KiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109373: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 11, Chunks in use: 11. 23.0KiB allocated for chunks. 23.0KiB in use in bin. 23.0KiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109377: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109381: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109385: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109388: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109392: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109396: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109401: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 744.2KiB allocated for chunks. 744.2KiB in use in bin. 512.0KiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109405: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 2, Chunks in use: 2. 1.41MiB allocated for chunks. 1.41MiB in use in bin. 1.41MiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109409: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 2. 3.36MiB allocated for chunks. 3.36MiB in use in bin. 2.75MiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109413: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109417: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109421: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 5, Chunks in use: 4. 52.86MiB allocated for chunks. 39.09MiB in use in bin. 39.09MiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109426: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 21.00MiB allocated for chunks. 21.00MiB in use in bin. 14.42MiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109433: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109437: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109441: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109444: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109449: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 90.48MiB was 64.00MiB, Chunk State: \n",
      "2023-01-18 18:43:34.109452: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 83283200\n",
      "2023-01-18 18:43:34.109459: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e000000 of size 256 next 1\n",
      "2023-01-18 18:43:34.109463: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e000100 of size 1280 next 2\n",
      "2023-01-18 18:43:34.109466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e000600 of size 256 next 3\n",
      "2023-01-18 18:43:34.109469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e000700 of size 256 next 4\n",
      "2023-01-18 18:43:34.109472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e000800 of size 256 next 6\n",
      "2023-01-18 18:43:34.109476: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e000900 of size 512 next 7\n",
      "2023-01-18 18:43:34.109479: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e000b00 of size 256 next 5\n",
      "2023-01-18 18:43:34.109482: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e000c00 of size 512 next 8\n",
      "2023-01-18 18:43:34.109485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e000e00 of size 512 next 11\n",
      "2023-01-18 18:43:34.109488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e001000 of size 512 next 12\n",
      "2023-01-18 18:43:34.109491: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e001200 of size 256 next 13\n",
      "2023-01-18 18:43:34.109494: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e001300 of size 256 next 14\n",
      "2023-01-18 18:43:34.109497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e001400 of size 1024 next 17\n",
      "2023-01-18 18:43:34.109501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e001800 of size 1792 next 9\n",
      "2023-01-18 18:43:34.109504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e001f00 of size 2560 next 10\n",
      "2023-01-18 18:43:34.109508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e002900 of size 1024 next 15\n",
      "2023-01-18 18:43:34.109511: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e002d00 of size 1024 next 16\n",
      "2023-01-18 18:43:34.109514: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e003100 of size 256 next 20\n",
      "2023-01-18 18:43:34.109517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e003200 of size 256 next 21\n",
      "2023-01-18 18:43:34.109520: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e003300 of size 2048 next 24\n",
      "2023-01-18 18:43:34.109523: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e003b00 of size 2048 next 22\n",
      "2023-01-18 18:43:34.109526: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e004300 of size 2048 next 23\n",
      "2023-01-18 18:43:34.109529: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e004b00 of size 2048 next 27\n",
      "2023-01-18 18:43:34.109532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e005300 of size 256 next 28\n",
      "2023-01-18 18:43:34.109536: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e005400 of size 256 next 29\n",
      "2023-01-18 18:43:34.109539: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e005500 of size 1024 next 31\n",
      "2023-01-18 18:43:34.109542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e005900 of size 1024 next 32\n",
      "2023-01-18 18:43:34.109545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e005d00 of size 1024 next 30\n",
      "2023-01-18 18:43:34.109548: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e006100 of size 256 next 33\n",
      "2023-01-18 18:43:34.109551: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e006200 of size 256 next 36\n",
      "2023-01-18 18:43:34.109554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e006300 of size 256 next 39\n",
      "2023-01-18 18:43:34.109557: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e006400 of size 256 next 37\n",
      "2023-01-18 18:43:34.109560: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e006500 of size 256 next 38\n",
      "2023-01-18 18:43:34.109563: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e006600 of size 256 next 41\n",
      "2023-01-18 18:43:34.109566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e006700 of size 256 next 42\n",
      "2023-01-18 18:43:34.109569: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e006800 of size 256 next 43\n",
      "2023-01-18 18:43:34.109573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e006900 of size 1792 next 44\n",
      "2023-01-18 18:43:34.109576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e007000 of size 256 next 45\n",
      "2023-01-18 18:43:34.109579: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e007100 of size 256 next 46\n",
      "2023-01-18 18:43:34.109582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e007200 of size 256 next 47\n",
      "2023-01-18 18:43:34.109585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e007300 of size 256 next 48\n",
      "2023-01-18 18:43:34.109588: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e007400 of size 256 next 49\n",
      "2023-01-18 18:43:34.109591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e007500 of size 2560 next 50\n",
      "2023-01-18 18:43:34.109594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e007f00 of size 512 next 51\n",
      "2023-01-18 18:43:34.109597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e008100 of size 512 next 52\n",
      "2023-01-18 18:43:34.109600: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e008300 of size 512 next 53\n",
      "2023-01-18 18:43:34.109603: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e008500 of size 512 next 54\n",
      "2023-01-18 18:43:34.109606: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e008700 of size 1024 next 55\n",
      "2023-01-18 18:43:34.109609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e008b00 of size 1024 next 56\n",
      "2023-01-18 18:43:34.109612: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e008f00 of size 1024 next 57\n",
      "2023-01-18 18:43:34.109615: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e009300 of size 1024 next 58\n",
      "2023-01-18 18:43:34.109618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e009700 of size 2048 next 60\n",
      "2023-01-18 18:43:34.109621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e009f00 of size 2048 next 61\n",
      "2023-01-18 18:43:34.109628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e00a700 of size 2048 next 62\n",
      "2023-01-18 18:43:34.109633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e00af00 of size 2048 next 63\n",
      "2023-01-18 18:43:34.109639: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e00b700 of size 499968 next 34\n",
      "2023-01-18 18:43:34.109644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e085800 of size 262144 next 35\n",
      "2023-01-18 18:43:34.109649: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e0c5800 of size 2085120 next 19\n",
      "2023-01-18 18:43:34.109655: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e2c2900 of size 1441792 next 18\n",
      "2023-01-18 18:43:34.109660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0e422900 of size 22020096 next 26\n",
      "2023-01-18 18:43:34.109670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0f922900 of size 11010048 next 25\n",
      "2023-01-18 18:43:34.109676: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf103a2900 of size 9486336 next 40\n",
      "2023-01-18 18:43:34.109681: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf10cae900 of size 11010048 next 59\n",
      "2023-01-18 18:43:34.109686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1172e900 of size 1024 next 64\n",
      "2023-01-18 18:43:34.109691: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1172ed00 of size 1024 next 65\n",
      "2023-01-18 18:43:34.109696: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1172f100 of size 1024 next 66\n",
      "2023-01-18 18:43:34.109701: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1172f500 of size 9486336 next 67\n",
      "2023-01-18 18:43:34.109706: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203b500 of size 256 next 68\n",
      "2023-01-18 18:43:34.109711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203b600 of size 256 next 69\n",
      "2023-01-18 18:43:34.109716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203b700 of size 256 next 70\n",
      "2023-01-18 18:43:34.109721: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203b800 of size 256 next 71\n",
      "2023-01-18 18:43:34.109726: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203b900 of size 256 next 72\n",
      "2023-01-18 18:43:34.109731: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203ba00 of size 256 next 73\n",
      "2023-01-18 18:43:34.109736: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203bb00 of size 256 next 74\n",
      "2023-01-18 18:43:34.109740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203bc00 of size 256 next 75\n",
      "2023-01-18 18:43:34.109745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203bd00 of size 256 next 76\n",
      "2023-01-18 18:43:34.109750: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203be00 of size 256 next 77\n",
      "2023-01-18 18:43:34.109755: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203bf00 of size 256 next 78\n",
      "2023-01-18 18:43:34.109760: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203c000 of size 256 next 79\n",
      "2023-01-18 18:43:34.109765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203c100 of size 256 next 80\n",
      "2023-01-18 18:43:34.109770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203c200 of size 256 next 81\n",
      "2023-01-18 18:43:34.109774: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203c300 of size 256 next 82\n",
      "2023-01-18 18:43:34.109779: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203c400 of size 256 next 83\n",
      "2023-01-18 18:43:34.109785: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_1_bfc) ran out of memory trying to allocate 90.48MiB (rounded to 94873600)requested by op replica_1/model/conv1d/Conv1D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-01-18 18:43:34.109813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203c500 of size 256 next 84\n",
      "2023-01-18 18:43:34.109820: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203c600 of size 256 next 85\n",
      "2023-01-18 18:43:34.109825: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203c700 of size 2048 next 86\n",
      "2023-01-18 18:43:34.109831: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203cf00 of size 512 next 87\n",
      "2023-01-18 18:43:34.109836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203d100 of size 1024 next 88\n",
      "2023-01-18 18:43:34.109841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203d500 of size 256 next 89\n",
      "2023-01-18 18:43:34.109846: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203d600 of size 256 next 90\n",
      "2023-01-18 18:43:34.109851: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf1203d700 of size 741376 next 91\n",
      "2023-01-18 18:43:34.109856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf120f2700 of size 256 next 92\n",
      "2023-01-18 18:43:34.109861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf120f2800 of size 741376 next 93\n",
      "2023-01-18 18:43:34.109866: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf121a7800 of size 256 next 94\n",
      "2023-01-18 18:43:34.109871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf121a7900 of size 256 next 95\n",
      "2023-01-18 18:43:34.109876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 14bf121a7a00 of size 14439168 next 18446744073709551615\n",
      "2023-01-18 18:43:34.109881: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-01-18 18:43:34.109887: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_1_bfc\n",
      "2023-01-18 18:43:34.109898: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 47 Chunks of size 256 totalling 11.8KiB\n",
      "2023-01-18 18:43:34.109906: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 33, Chunks in use: 32. 8.2KiB allocated for chunks. 8.0KiB in use in bin. 364B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109914: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 9 Chunks of size 512 totalling 4.5KiB\n",
      "2023-01-18 18:43:34.109922: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 9, Chunks in use: 9. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 4.5KiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109929: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 14 Chunks of size 1024 totalling 14.0KiB\n",
      "2023-01-18 18:43:34.109936: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 16, Chunks in use: 16. 16.2KiB allocated for chunks. 16.2KiB in use in bin. 16.0KiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109944: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-01-18 18:43:34.109951: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 11, Chunks in use: 11. 23.0KiB allocated for chunks. 23.0KiB in use in bin. 23.0KiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.109958: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 1792 totalling 3.5KiB\n",
      "2023-01-18 18:43:34.109966: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 9 Chunks of size 2048 totalling 18.0KiB\n",
      "2023-01-18 18:43:34.109971: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 2560 totalling 5.0KiB\n",
      "2023-01-18 18:43:34.109977: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 262144 totalling 256.0KiB\n",
      "2023-01-18 18:43:34.109983: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 499968 totalling 488.2KiB\n",
      "2023-01-18 18:43:34.109988: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 741376 totalling 1.41MiB\n",
      "2023-01-18 18:43:34.109994: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1441792 totalling 1.38MiB\n",
      "2023-01-18 18:43:34.109999: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2085120 totalling 1.99MiB\n",
      "2023-01-18 18:43:34.110005: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110012: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 9486336 totalling 18.09MiB\n",
      "2023-01-18 18:43:34.110020: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110027: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110033: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110038: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 11010048 totalling 21.00MiB\n",
      "2023-01-18 18:43:34.110045: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110051: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 22020096 totalling 21.00MiB\n",
      "2023-01-18 18:43:34.110058: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110064: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 65.65MiB\n",
      "2023-01-18 18:43:34.110070: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 512.0KiB allocated for chunks. 512.0KiB in use in bin. 512.0KiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110078: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 2, Chunks in use: 2. 1.41MiB allocated for chunks. 1.41MiB in use in bin. 1.41MiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110084: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 83283200 memory_limit_: 92536832 available bytes: 9253632 curr_region_allocation_bytes_: 185073664\n",
      "2023-01-18 18:43:34.110091: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 2. 2.75MiB allocated for chunks. 2.75MiB in use in bin. 2.75MiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110098: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        92536832\n",
      "InUse:                        68844032\n",
      "MaxInUse:                     69585664\n",
      "NumAllocs:                         125\n",
      "MaxAllocSize:                 22020096\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-01-18 18:43:34.110106: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110110: W tensorflow/tsl/framework/bfc_allocator.cc:492] ************************xxxxxxx****************************************************_________________\n",
      "2023-01-18 18:43:34.110118: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110124: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 4, Chunks in use: 4. 39.09MiB allocated for chunks. 39.09MiB in use in bin. 39.09MiB client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110128: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110132: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 35.62MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110136: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110140: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110145: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-18 18:43:34.110152: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:698 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[10,128,1,18530] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2023-01-18 18:43:34.110160: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 90.48MiB was 64.00MiB, Chunk State: \n",
      "2023-01-18 18:43:34.110165: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 83283200\n",
      "2023-01-18 18:43:34.110171: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08000000 of size 256 next 1\n",
      "2023-01-18 18:43:34.110174: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08000100 of size 1280 next 2\n",
      "2023-01-18 18:43:34.110178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08000600 of size 2560 next 3\n",
      "2023-01-18 18:43:34.110181: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08001000 of size 512 next 4\n",
      "2023-01-18 18:43:34.110184: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08001200 of size 512 next 5\n",
      "2023-01-18 18:43:34.110188: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08001400 of size 512 next 6\n",
      "2023-01-18 18:43:34.110191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08001600 of size 512 next 7\n",
      "2023-01-18 18:43:34.110194: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08001800 of size 1441792 next 8\n",
      "2023-01-18 18:43:34.110198: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08161800 of size 1024 next 9\n",
      "2023-01-18 18:43:34.110201: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08161c00 of size 1024 next 10\n",
      "2023-01-18 18:43:34.110204: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08162000 of size 1024 next 11\n",
      "2023-01-18 18:43:34.110207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08162400 of size 1024 next 12\n",
      "2023-01-18 18:43:34.110210: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08162800 of size 11010048 next 13\n",
      "2023-01-18 18:43:34.110214: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08be2800 of size 2048 next 14\n",
      "2023-01-18 18:43:34.110217: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08be3000 of size 2048 next 15\n",
      "2023-01-18 18:43:34.110220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08be3800 of size 2048 next 16\n",
      "2023-01-18 18:43:34.110223: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08be4000 of size 2048 next 17\n",
      "2023-01-18 18:43:34.110227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08be4800 of size 262144 next 18\n",
      "2023-01-18 18:43:34.110230: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08c24800 of size 1024 next 19\n",
      "2023-01-18 18:43:34.110233: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08c24c00 of size 1024 next 20\n",
      "2023-01-18 18:43:34.110236: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08c25000 of size 1024 next 21\n",
      "2023-01-18 18:43:34.110239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf08c25400 of size 9486336 next 22\n",
      "2023-01-18 18:43:34.110243: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531400 of size 256 next 23\n",
      "2023-01-18 18:43:34.110246: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531500 of size 256 next 24\n",
      "2023-01-18 18:43:34.110249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531600 of size 256 next 25\n",
      "2023-01-18 18:43:34.110252: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531700 of size 256 next 26\n",
      "2023-01-18 18:43:34.110255: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531800 of size 256 next 27\n",
      "2023-01-18 18:43:34.110258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531900 of size 256 next 28\n",
      "2023-01-18 18:43:34.110261: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531a00 of size 256 next 29\n",
      "2023-01-18 18:43:34.110264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531b00 of size 256 next 30\n",
      "2023-01-18 18:43:34.110268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531c00 of size 256 next 31\n",
      "2023-01-18 18:43:34.110271: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531d00 of size 256 next 32\n",
      "2023-01-18 18:43:34.110274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531e00 of size 256 next 33\n",
      "2023-01-18 18:43:34.110277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09531f00 of size 2560 next 34\n",
      "2023-01-18 18:43:34.110280: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09532900 of size 512 next 35\n",
      "2023-01-18 18:43:34.110283: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09532b00 of size 512 next 36\n",
      "2023-01-18 18:43:34.110286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09532d00 of size 512 next 37\n",
      "2023-01-18 18:43:34.110289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09532f00 of size 512 next 38\n",
      "2023-01-18 18:43:34.110293: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09533100 of size 1441792 next 39\n",
      "2023-01-18 18:43:34.110296: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09693100 of size 1024 next 40\n",
      "2023-01-18 18:43:34.110299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09693500 of size 1024 next 41\n",
      "2023-01-18 18:43:34.110302: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09693900 of size 1024 next 42\n",
      "2023-01-18 18:43:34.110305: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09693d00 of size 1024 next 43\n",
      "2023-01-18 18:43:34.110308: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf09694100 of size 11010048 next 44\n",
      "2023-01-18 18:43:34.110311: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0a114100 of size 2048 next 45\n",
      "2023-01-18 18:43:34.110315: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0a114900 of size 2048 next 46\n",
      "2023-01-18 18:43:34.110318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0a115100 of size 2048 next 47\n",
      "2023-01-18 18:43:34.110321: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0a115900 of size 2048 next 48\n",
      "2023-01-18 18:43:34.110324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0a116100 of size 262144 next 49\n",
      "2023-01-18 18:43:34.110327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0a156100 of size 1024 next 50\n",
      "2023-01-18 18:43:34.110330: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0a156500 of size 1024 next 51\n",
      "2023-01-18 18:43:34.110333: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0a156900 of size 1024 next 52\n",
      "2023-01-18 18:43:34.110337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0a156d00 of size 9486336 next 53\n",
      "2023-01-18 18:43:34.110340: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa62d00 of size 256 next 54\n",
      "2023-01-18 18:43:34.110343: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa62e00 of size 256 next 55\n",
      "2023-01-18 18:43:34.110346: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa62f00 of size 256 next 56\n",
      "2023-01-18 18:43:34.110349: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63000 of size 256 next 57\n",
      "2023-01-18 18:43:34.110352: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63100 of size 256 next 58\n",
      "2023-01-18 18:43:34.110355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63200 of size 256 next 59\n",
      "2023-01-18 18:43:34.110358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63300 of size 256 next 60\n",
      "2023-01-18 18:43:34.110361: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63400 of size 256 next 61\n",
      "2023-01-18 18:43:34.110365: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63500 of size 256 next 62\n",
      "2023-01-18 18:43:34.110368: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63600 of size 256 next 63\n",
      "2023-01-18 18:43:34.110371: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63700 of size 256 next 64\n",
      "2023-01-18 18:43:34.110374: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63800 of size 256 next 65\n",
      "2023-01-18 18:43:34.110377: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63900 of size 256 next 66\n",
      "2023-01-18 18:43:34.110380: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63a00 of size 256 next 67\n",
      "2023-01-18 18:43:34.110383: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63b00 of size 256 next 68\n",
      "2023-01-18 18:43:34.110386: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63c00 of size 256 next 69\n",
      "2023-01-18 18:43:34.110389: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa63d00 of size 2048 next 70\n",
      "2023-01-18 18:43:34.110393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa64500 of size 512 next 71\n",
      "2023-01-18 18:43:34.110396: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa64700 of size 1024 next 72\n",
      "2023-01-18 18:43:34.110399: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0aa64b00 of size 741632 next 74\n",
      "2023-01-18 18:43:34.110402: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0ab19c00 of size 741376 next 75\n",
      "2023-01-18 18:43:34.110406: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0abcec00 of size 256 next 73\n",
      "2023-01-18 18:43:34.110409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0abced00 of size 256 next 76\n",
      "2023-01-18 18:43:34.110412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 14bf0abcee00 of size 256 next 77\n",
      "2023-01-18 18:43:34.110415: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0abcef00 of size 256 next 78\n",
      "2023-01-18 18:43:34.110418: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 14bf0abcf000 of size 256 next 79\n",
      "2023-01-18 18:43:34.110422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 14bf0abcf100 of size 37346304 next 18446744073709551615\n",
      "2023-01-18 18:43:34.110425: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-01-18 18:43:34.110429: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 32 Chunks of size 256 totalling 8.0KiB\n",
      "2023-01-18 18:43:34.110433: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 9 Chunks of size 512 totalling 4.5KiB\n",
      "2023-01-18 18:43:34.110436: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 15 Chunks of size 1024 totalling 15.0KiB\n",
      "2023-01-18 18:43:34.110440: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-01-18 18:43:34.110444: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 9 Chunks of size 2048 totalling 18.0KiB\n",
      "2023-01-18 18:43:34.110447: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 2560 totalling 5.0KiB\n",
      "2023-01-18 18:43:34.110451: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 262144 totalling 512.0KiB\n",
      "2023-01-18 18:43:34.110455: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 741376 totalling 724.0KiB\n",
      "2023-01-18 18:43:34.110459: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 741632 totalling 724.2KiB\n",
      "2023-01-18 18:43:34.110463: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 1441792 totalling 2.75MiB\n",
      "2023-01-18 18:43:34.110466: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 9486336 totalling 18.09MiB\n",
      "2023-01-18 18:43:34.110470: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 11010048 totalling 21.00MiB\n",
      "2023-01-18 18:43:34.110474: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 43.81MiB\n",
      "2023-01-18 18:43:34.110478: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 83283200 memory_limit_: 92536832 available bytes: 9253632 curr_region_allocation_bytes_: 185073664\n",
      "2023-01-18 18:43:34.110487: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        92536832\n",
      "InUse:                        45936640\n",
      "MaxInUse:                     45936896\n",
      "NumAllocs:                          83\n",
      "MaxAllocSize:                 11010048\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-01-18 18:43:34.110494: W tensorflow/tsl/framework/bfc_allocator.cc:492] ********************************************************____________________________________________\n",
      "2023-01-18 18:43:34.110506: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:698 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[10,128,1,18530] and type float on /job:localhost/replica:0/task:0/device:GPU:1 by allocator GPU_1_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/lib64/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/usr/lib64/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/lib64/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/usr/lib64/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/lib64/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/usr/lib64/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\n3 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[10,128,1,18530] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv1d/Conv1D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[update_0_22/AssignAddVariableOp/_153]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[div_no_nan/ReadVariableOp_1/_130]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[10,128,1,18530] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv1d/Conv1D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[update_0_22/AssignAddVariableOp/_153]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (2) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[10,128,1,18530] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv1d/Conv1D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_6622]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(input_size, output_size)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSGD\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mTqdmCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# TODO: add confusion matrix\u001b[39;00m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/lib64/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/usr/lib64/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/lib64/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/usr/lib64/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/lib64/python3.8/threading.py\", line 890, in _bootstrap\n      self._bootstrap_inner()\n    File \"/usr/lib64/python3.8/threading.py\", line 932, in _bootstrap_inner\n      self.run()\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 283, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/bwhpc/common/jupyter/tensorflow/2023-01-02/lib/python3.8/site-packages/keras/layers/convolutional/base_conv.py\", line 255, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\n3 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[10,128,1,18530] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv1d/Conv1D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[update_0_22/AssignAddVariableOp/_153]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[div_no_nan/ReadVariableOp_1/_130]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[10,128,1,18530] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv1d/Conv1D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[update_0_22/AssignAddVariableOp/_153]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (2) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[10,128,1,18530] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv1d/Conv1D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_6622]"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    for ds_name, ds_data in tqdm(datasets_test_train_data.items(), unit='dataset'):\n",
    "        print(\"Dataset name: \", ds_name)\n",
    "        x_test, y_test = ds_data[\"test_data\"]\n",
    "        x_train, y_train = ds_data[\"train_data\"]\n",
    "\n",
    "        input_size = x_train.shape[1]\n",
    "        output_size = len(np.unique(y_train))\n",
    "\n",
    "        for get_model, model_name in tqdm(list(zip(models_getter, models_names)), unit='model', desc=f'Train on \"{ds_name}\"'):\n",
    "            print(\"Model name: \", model_name)\n",
    "            model = get_model(input_size, output_size)\n",
    "            model.compile(optimizer='SGD',\n",
    "                          loss='sparse_categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "            history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=[TqdmCallback(verbose=0, desc=model_name)], verbose=0)\n",
    "            test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "            # TODO: add confusion matrix\n",
    "\n",
    "            row = [ds_name,\n",
    "                  model_name,\n",
    "                  test_loss,\n",
    "                  test_acc,\n",
    "                  None, # TODO: persist confusion matrix to further analysis\n",
    "                  json.dumps(history.history)]\n",
    "            append_to_csv(path_persist_results, row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example load training results and display evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_training_res = pd.read_csv(path_persist_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_training_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "history = df_training_res['history'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_model_history(json.loads(history), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_ensemble",
   "language": "python",
   "name": "ts_ensemble"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
